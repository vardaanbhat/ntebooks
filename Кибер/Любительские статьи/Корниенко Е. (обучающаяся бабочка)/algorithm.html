<html><head>


<meta http-equiv="Content-Type" content="text/html; charset=windows-1251">
<meta name="author" content="Eugeny Kornienko">
<meta name="keywords" content="интеллект, алгоритм, программирование, творчество, мозг, робот, обучение,
сознание, автоматический, ощущения, информация, правила, инстинкт, опыт, 
рецептор, восприятие, понимание, искусственный, разум, самообучение, адаптация, поведение, условный рефлекс, 
смысл, узнавание, самоорганизация, ассоциативный, осознавание, знание, стимул, 
повторение, повтор, память">
<meta name="description" content="Одновременное исполнение ранее не синхронных процессов обеспечивает прохождение этим алгоритмом теста на осознавание себя."><title>Алгоритм самообучения</title></head><body background="algorithm_files/sky.jpg" bgcolor="#fffff0">

<p><a href="http://webcenter.ru/%7Ekorn/index.html"><img src="algorithm_files/logo-ru.gif" alt="Механизмы... Е.Корниенко" border="0" height="33" width="408"></a></p>

<blockquote>
 <p align="center"><small><!--webbot bot="Navigation" S-Type="siblings" S-Orientation="horizontal" S-Rendering="text" B-Include-Home="FALSE" B-Include-Up="FALSE" startspan --><nobr>[&nbsp;<a href="http://webcenter.ru/%7Ekorn/mind/task.html">Техническое&nbsp;задание</a>&nbsp;]</nobr> <nobr>[&nbsp;<a href="http://webcenter.ru/%7Ekorn/mind/sense.html">Происхождение&nbsp;мышления</a>&nbsp;]</nobr> <nobr>[&nbsp;Алгоритм&nbsp;самообучения&nbsp;]</nobr><!--webbot bot="Navigation" endspan i-checksum="31164" --></small></p>
</blockquote>

<hr width="80%">
<div align="right">

<table border="0" width="40%">
 <tbody><tr>
 <td bgcolor="#ffffff" width="40%"><p align="center">Одновременное
 исполнение нескольких процессов, сохранённых в
 памяти в разное время, обеспечивает прохождение
 этим алгоритмом <strong>теста на осознавание себя.</strong></p></td>
 </tr>
</tbody></table>
</div>

<h1>Алгоритм самообучения</h1>

<p>Доказательством понимания природы и главных
принципов работы сознания могло бы служить
возникновение сознания у специально созданного
искусственного существа.</p>

<p> </p>

<h3>Требуется построить ощущающую машину</h3>

<p>Мы считаем себя обладающими сознанием,
например, потому, что мы способны контролировать
и обдумывать свои действия. Более простая форма
сознания заключается в способности осознавать,
то есть ощущать свои действия и их последствия.
Ещё более простой формой сознания является
способность хотя бы осознавать свои ощущения,
что мы коротко обозначаем словом "ощущать".</p>

<p>Поэтому доказательством понимания основ
сознания было бы построение ощущающей машины. Её
можно будет назвать сознательным существом, если
она будет осознавать не только ощущения, но и
свои действия, и, тем более, если она сможет
обдумывать и планировать свои действия.</p>

<p>Ощущение - это простейшая форма сознания. По
мере накопления опыта ощущения детализируются,
формируются навыки поведения, развивается
осознание взаимосвязи ощущений и действий.</p>

<p>Явными признаками сознания являются
интеллектуальные способности, в частности,
творчество и способность к обучению. Связь
обучения с ощущением прослеживается в <em><a href="http://webcenter.ru/%7Ekorn/mind/consciousness.html#test">тесте на самообучение</a></em>. Из
способности к самообучению следует наличие
внутреннего стремления к определённому
состоянию - самоощущению. </p>

<p>Желаемое внутреннее состояние можно считать
заданной от природы <em>безусловной потребностью</em>.
Технически, можно ввести целевую функцию W,
пропорциональную <em>потребности</em> и зависящую
только от состояния S сенсоров машины.
Минимальное значение этой функции соответствует
минимальной потребности. Оно может быть
достигнуто в результате <em>полезного</em>
поведения. В процессе самообучения заданная
целевая функция W постепенно убывает.</p>

<p>Если поведение не задано программными и
конструктивными средствами, то в процессе
самообучения у существа развиваются ощущения
качеств внешнего мира, зависящих от поведения и
влияющих на общее состояние этого существа.
Ощущение – это субъективное <em>измерение</em>
своего состояния, необходимое при поиске
желательного состояния. Наблюдаемая извне
оптимизация (рационализация) поведения, то есть
самообучение, субъективно состоит в улучшении
самоощущения, а объективно – в уменьшении
потребности.</p>

<p>Творчество и самообучение - это способности к
самостоятельному поиску <em>полезного поведения</em>,
приводящего к удовлетворению врождённых,
безусловных потребностей.</p>

<p>Обучение (с учителем) – это создание
специальных условий, при которых самообучение
приводит к выработке поведения, <em>полезного</em>
не только ученику, но и учителю.</p>

<p>Самообучение ещё называется способностью к <em>универсальному</em>
научению, которое состоит в том, что целевая
функция W убывает при произвольно заданном
(например, случайном) начальном поведении и при
любых законах мира – машина <em>выводит</em>
полезное поведение из любого изначально
заданного. Универсальное обучение или
самообучение - это обучение без внешней
мотивации того, что и как надо учить.</p>

<p>Достаточно легко проверяемое у машины
отсутствие встроенных алгоритмов,
приспособленных к определённому внешнему миру,
является первой ступенью доказательства наличия
субъективных, а не автоматических
(алгоритмических, механических, конструктивно
обусловленных) стремлений.</p>

<p>О способностях машины мы будем судить по её <em>поведению</em>,
так как невозможно объективно проверить наличие
ощущений у другого субъекта. Доказательство
возникновения сознания должно исходить из
особенностей конструкции и из заключения
скептически настроенного эксперта. Мы можем
предлагать тесты и способы доказательства, но
только независимый эксперт проверяет, что наша
машина обладает сознанием. Он сам должен
убедиться в том, что наша машина обладает
творчеством, испытывает эмоции по поводу своих
действий и нашего отношения к ней.</p>

<p> </p>

<h3>Направление поиска</h3>

<p>Сознание человека реализовано победившими в
эволюционной борьбе биологическими средствами.
При другом стечении обстоятельств мы могли бы
иметь несколько отличающуюся или совсем другую
систему для информационного обмена между
органами вместо нервной системы и другой орган
для централизованного управления организмом
вместо мозга.</p>

<p>Возможность функционального объяснения
явлений сознания предполагает, что одинаковые
функции могут исполняться различными
техническими средствами. Эта идея позволяет не
ограничивать себя подражанием природе. В
частности, не обязательно размещать в центре
искусственного разума мозг из нейронных сетей,
имитирующий живой мозг, если окажется, что без
этого можно обойтись. В конце концов, природа
создавала нас путём случайных попыток, и могла
найти не самое оптимальное решение.</p>

<p>Конечно, и я придумал не самый оптимальный
алгоритм и требования к организации работы
органов, обеспечивающих работу субъективного
сознания. Это - один из возможных вариантов
самообучающейся машины.</p>

<p>Незавершённое решение сложной задачи – это
"живой организм". Подходы, формулировки,
пути решения, выводы постоянно изменяются.
Проводятся опыты. Делаются попытки формализации
того, что раньше объяснялось на словах или вовсе
не объяснялось, так как некоторые вопросы только
возникают в результате исследования. У меня есть<em>
<a href="http://webcenter.ru/%7Ekorn/study/index.html">рабочие записи</a></em>, в которых
можно обнаружить долго прорабатываемые
проблемы, о которых я вообще никогда не упоминал.
Можно найти нерешённые промежуточные и
перспективные задачи. Есть решённые задачи и
удовлетворительные ответы.</p>

<p>Я попробую объяснить устройство ощущающего
существа путём постепенной детализации задачи о
построении самообучающейся машины. В какой-то
момент множество деталей станет отвлекать от
основной цели работы. Тогда нужно будет
пропустить этап детализации, и перейти к
обсуждению алгоритма и его реализации.</p>

<p>Вместо постепенного введения существенных
терминов и понятий, я буду использовать их с
самого начала, и буду уточнять их значение только
в силу необходимости их конкретного применения.
Вы можете заметить противоречия в трактовке
некоторых понятий. Считайте, что их определения
сформулированы <em>в первом приближении</em> и ещё
требуют согласования.</p>

<p>К примеру, термины <em>прогноз</em> или <em>поведение,
</em>используются как в обычном широком, так и в
алгоритмическом смысле, и нужно выполнить
плавный переход от одного понимания к другому. В
алгоритме нет разницы между сенсорами и
эффекторами. Поэтому прогнозирование относится
как к поведению, так и к восприятию. Попробуйте
объединить традиционно активное <em>поведение</em>
и пассивное <em>ощущение</em>, и у вас сначала тоже
возникнут противоречия.</p>

<p>Почему я предпочитаю "сознание"
традиционному понятию "искусственный
интеллект"? Зачем называть кибернетическую
систему существом? Не выдаю ли я желаемое за
действительное? Как эти естественные вопросы,
так и ответы ещё потребуют разъяснений.</p>

<p>Значение термина "искусственный
интеллект" зависит от контекста. Меня
интересует та часть задачи, которая
рассматривает возможность создания
искусственного сознания, создания чувствующей и
осознающей свои ощущения машины. О том, как
сознание и интеллект развивается из ощущений
рассказано в статье " <a href="http://webcenter.ru/%7Ekorn/mind/consciousness.html">Механизмы
сознания</a>" и на других страницах сайта.</p>

<p>Я не могу обойтись без таких терминов, как
сознание и ощущение ещё и потому, что
разрабатываемый алгоритм не предназначен для
решения определённой технической задачи ИИ,
вроде идентификации почерка, распознавания
текста, или "смыслового" поиска в базе
данных. Алгоритм по существу не конкретен и
вообще не задаёт никакой предписанной реакции на
входные данные.</p>

<p>Смысл подхода, совмещающего такие
противоречивые понятия, как абстрактность и
алгоритм, не удаётся объяснить чисто технически,
без ссылок на философские и психологические
аргументы.</p>

<p>В частности, машину, имеющую субъективные
ощущения, естественно называть существом. К
этому слову нужно относиться как к основному
требованию поставленной задачи. Что получится в
результате – машина или существо – это тема
отдельного исследования, которое само может
изменить наши понятия о разуме в применении к
машине.</p>

<p> </p>

<h3>Объективный внешний мир</h3>

<p>Об уровне интеллекта и о возможных ощущениях
машины можно судить только наблюдая и изучив её <em>поведение</em>,
то есть её взаимодействие с внешним миром, в том
числе с нами.</p>

<p>Обычное понятие поведения подразумевает
заинтересованность в результате, а не просто
взаимодействие. Строго говоря, <em>заинтересованность</em>
является свойством субъекта и скрыта от
стороннего наблюдателя. Она может проявиться
через характерные признаки поведения. Эти
признаки зависят от характера целевой функции,
физических особенностей организма, особенностей
<em>алгоритма</em> универсального обучения, (и от
нашей способности к их интерпретации :).</p>

<p>Для методического упрощения задачи можно дать
машине искусственный внешний мир. Однако
предопределённые рациональные свойства
искусственного мира можно ошибочно принять за
интеллектуальное достижение машины, так как
иногда трудно отделить <em>поведение мира</em> от
поведения существа в их взаимодействии. Поэтому
в перспективе требуются испытания в реальном
мире, <em>окружающем</em> и нас и наше искусственное
существо. </p>

<p>Свойства физического мира не зависят от меня,
что особенно важно для беспристрастного
испытания искусственного интеллекта.
Объективность внешнего мира означает, что его
свойства не зависят от сознания и от внутренней
модели мира.</p>

<p> </p>

<h3>Сознание и тело</h3>

<p align="center"><img src="algorithm_files/al01.gif" alt="Сознание идеально, но почему-то оно может влиять на физический мир. И, тем более, мир влияет на сознание." height="239" width="502">
</p>

<p>Сознание не является физическим объектом и не
имеет геометрической связи с физическим миром.
Можно считать, что объективный мир является
внешним по отношению к сознанию в том смысле, что
сознание является частью <em>всего мира </em>(этот
термин объясняется в статье "<font size="3"><a href="http://webcenter.ru/%7Ekorn/world/space.html"><strong>Основы натуральной философии</strong></a></font>").
<em>Законы внешнего мира</em> не зависят от сознания,
в то время как сознание зависит от мира и
отражает его. Однако локальные свойства мира
зависят от материализованной активности
(сознательного) существа или машины. </p>

<p>Физическое тело существа, обладающего
сознанием, включая его мозг и прочие органы,
является геометрически вложенным в мир. Можно
говорить о внешнем или окружающем мире, как о
части мира вне тела.</p>

<p>Тело не обязательно имеет физическую форму,
например, оно может быть <em>информационным</em> на
физическом или на информационном же носителе.
Тело такого эфемерного существа остаётся частью
объективного мира и служит носителем органов,
мозга и других систем, обеспечивающих работу
идеального сознания. Об относительности понятий <em>идеального</em>
и <em>материального</em> можно почитать в заметке <a href="http://webcenter.ru/%7Ekorn/study/process.html">"Как идеальное возникает из
материального?"</a></p>

<p>В общем, понятие тела тоже условно, и
используется здесь в качестве объединяющего
названия для органов и системы управления,
которые не обязаны геометрически находиться в
пределах легко узнаваемого <em>физического
организма</em>.</p>

<p>Если существо имеет физическое тело, то у него
могут быть внешние органы, взаимодействующие с
внешним миром, и внутренние органы, определяющие
(или влияющие на) внутренние физические
параметры тела. Функционально, внутренние органы
не отличаются от геометрически внешних органов и
взаимодействуют с миром и друг с другом,
физическими средствами.</p>

<p> </p>

<h3>Органы и мозг</h3>

<p>Любое устройство, преобразующее воздействие в
код, или код в воздействие, может служить
органом-сенсором или исполнительным органом
машины. Для обеспечения универсального обучения
органы должны обладать особыми свойствами,
которые имеются не у любого преобразователя.
Оптимальная конструкция и особые функции
датчиков-преобразователей, превращающие их в
эффективные органы, следуют из разграничения
доступа к объектам и данным между мозгом,
органами и внешним миром, которое требуется для
обеспечения универсальности мозга.</p>

<p>Мозг общается с органами через каналы связи,
аналогичные нервной системе. Нервную систему
лучше считать не органом, а информационным
транспортом и хранилищем данных. Рассматривая
нервную систему и мозг как часть системы
управления, взаимодействующей с органами, а не с
внешним миром, мы можем условно считать нервную
систему интерфейсом между сознанием и органами.
Эта идея противоречит нелокализуемости
сознания, но она помогает разделить функции
органов и мозга при их проектировании.</p>

<p>Связь органов с внешним миром может быть
физической или информационной в зависимости от
природы этого мира. Связь материальных органов,
посредством нервной системы, с материальным
мозгом уже можно считать не физической, а
информационной, что соответствует современным
представлениям о роли мозга в организме. </p>

<p>Указанная выше условная связь универсального
мозга с сознанием является не информационной, а <em>абстрактно-ассоциативной</em>.
Субъект наблюдает внешний мир через калейдоскоп
ассоциативной игры мозга с <em>хранящимся в</em> <em>памяти</em>
прежним опытом субъекта<em>.</em> Субъективное
наблюдение воспринимается в виде форм сознания
– образов, идей, ощущений.</p>

<p align="center"><img src="algorithm_files/al02.gif" alt="Связь сознания с миром ассоциативна и не конкретна. Многие &quot;знания&quot; о мире не содержатся в сознании, а всякий раз заново реконструируются при помощи самого внешнего мира." height="248" width="531"></p>

<p>Сознание взаимодействует с миром при помощи
органов, используя <em>ассоциативную связь</em>.
Органы физически взаимодействуют с внешней по
отношению к ним частью мира, в том числе и друг с
другом, по общим законам взаимодействия частей
мира. </p>

<p>О том, в каком смысле идеальное сознание
включено в цепь физических взаимодействий,
говорится в заметке "<a href="http://webcenter.ru/%7Ekorn/mind/ideal.html">Детерминизм и
свобода воли</a>".</p>

<p> </p>

<h3>Универсальный мозг</h3>

<p>Реальная связь тело-сознание, в отличие от
физической или информационной связи, не
поддаётся формализации из-за своей
абстрактности. Используемая в работе
универсального мозга формализация не может
ссылаться на конкретные, представимые
средствами сознания образы, например, понятия. И
не может ссылаться на представимые средствами
объективного мира внешние объекты, например, на
изображения символов. </p>

<p>Когда я пишу этот текст, то работаю с понятиями
и символами. В это время мозг принимает и выдаёт
нервные сигналы, а руки преобразуют нервные
импульсы в движения. Понятия, нервные сигналы и
движения связаны друг с другом только благодаря
тому, что они направлены на взаимодействие с
одним и тем же внешним миром. Они <em>отражают</em>
один и тот же объективный мир, но имеют
несводимую друг к другу внутреннюю природу. </p>

<p>"Неформализуемость основ формализма"
является другим выражением несводимости
материального и идеального, и имеет
неконструктивный характер, то есть не
препятствует построению универсального мозга и
ощущающей машины и возникновению ощущающих
существ в природе.</p>

<p>Конструктивным следствием неформализуемости
сознания является то, что его не нужно
"формализовать" для обеспечения
субъективных ощущений у машины. В частности, не
нужно имитировать структуру внешнего мира в
памяти. </p>

<p>В моём алгоритме, абстрактность мозга по
отношению к текущему состоянию машины состоит в
том, что он ассоциативно оперирует только
прошлым опытом. В отличие от универсального
мозга сознание воспринимает конкретное
ощущаемое состояние (в контексте всего прошлого
опыта) в форме образов взаимодействия с внешним
миром. Текущее состояние может инициировать
образы как прошлого, так и предполагаемого
будущего.</p>

<p> </p>

<h3>Специализированные органы</h3>

<p>Органы, приспособленные к выполнению
определённых физических преобразований,
являются источниками ощущений (качеств внешнего
мира) для сознания.</p>

<p>Органы конкретны. Их функция преобразования
воздействие-код не обязательно зависит от
предыстории. Сознание менее конкретно. Оно
интерпретирует своё текущее состояние,
используя прошлый опыт. Мозг является
абстрактным в том смысле, что он вообще не
использует текущее состояние органов.</p>

<p>Нервная система, <em>память</em> и мозг не имеют
прямой связи ни с внешним миром, ни с сознанием.
Для них физический мир так же эфемерен, как и
сознание. Формализованная связь сознания с миром
в форме мышления возникает на поздних этапах
развития сознания.</p>

<p> </p>

<h3>Функции органов</h3>

<p>Активность машины проявляется в её действиях,
поведении, зависящем от её состояния и от
локальных свойств мира. Поведение
осуществляется при помощи органов действия,
исполнительных механизмов, которые мы назовём
"эффекторами". Воспринимающие (пассивные)
органы - это "сенсоры".</p>

<p>Поскольку универсальный мозг не может хранить
конкретные данные, то функция запоминания
передаётся интерфейсу между мозгом и органами
или самим органам. В последнем случае органы
самообучающейся машины являются
датчиками-преобразователями, способными
накапливать в памяти последовательность кодов,
выполнять некоторые функции по выбору данных из
памяти, в частности, сравнивать текущие и прежние
значения кодов. Такой орган, сам по себе, без
обращения к мозгу, обладает когнитивными
свойствами, так как имеет средства сравнения
прежних и текущих данных. Орган даже может иметь
свой информационный процессор - мозг.
Использование централизованного мозга – это
только один из способов организации
кооперативной работы органов.</p>

<p>Сенсоры измеряют доступные им свойства мира S(t)
и преобразуют результат измерения в функцию-код
s(t). S(t) - это не свойство мира в буквальном смысле,
а то, что воспринимает сенсор – <em>состояние или
показание сенсора.</em></p>

<p>Эффекторы преобразуют поток команд e(t) в
действия по отношению к миру E(t). E(t) также
является свойством или <em>состоянием</em>
эффектора. </p>

<p>Строго говоря, E(t) – это не само физическое
действие, а то, что должен выполнить эффектор,
если это позволят законы внешнего мира и текущее
состояние эффектора. При успешном выполнении
функцию E(t) можно трактовать, как само действие.
При одном и том же состоянии эффектора E(t)
физические действия могут различаться в
зависимости от состояния мира. </p>

<p>Органы взаимодействуют друг с другом как через
внешние, реальные каналы связи E(t) --&gt; S(t) (через
внешний мир), так и через внутренние,
информационные каналы s(t) --&gt; e(t) (через систему
управления).</p>

<p><strong>Поведение</strong> машины – это её действия E(t)
в зависимости от её состояния S(t). Обозначим
поведение как преобразование S(t) --&gt; E(t). Машине
недоступны никакие другие сведения о мире, кроме
тех, которые представимы через S(t). Действия E(t)
тоже несут информацию о внешнем мире, хотя бы
потому, что определённое состояние мира требует
определённых действий. </p>

<p>Воспринимаемое<strong> поведение мира</strong> E(t) --&gt;
S(t) определяется законами мира. Мы не
конструируем мир и не интересуемся причинами
определённого поведения мира. Может быть, мир
тоже содержит свою "систему управления". </p>

<p>При таком определении объект может иметь
поведение <em>по отношению к миру</em>, а мир - <em>по
отношению к опыту (внутреннему миру) объекта</em>. <em>Взаимодействие</em>
происходит между конкретными объектами, а <em>поведение</em>
– между одним объектом и всеми прочими объектами
в мире, которые рассматриваются как <em>внешний
мир</em>. При таком толковании термин
"поведение", пока ещё отличается от термина
"заинтересованное поведение".</p>

<p>Умышленное (заинтересованное, осознаваемое)
поведение возникает в силу стремления машины
оптимизировать заданную целевую <em>функцию
состояния</em> W в условиях взаимодействия с
реальным миром.</p>

<p>Целевая функция W может формироваться
специальными сенсорами Sw, анализирующими общее
состояние системы. В общем случае можно
вырабатывать сигнал W не путём прямого измерения,
а путём расчёта по данным других датчиков W=W(S,E).
При этом значения W(t) полностью определяются
показаниями (кодами, сигналами) датчиков s(t) и e(t).</p>

<p> </p>

<h3>Система управления</h3>

<p><em>Система управления</em> самообучающейся
машины<em> </em>состоит из <em>абстрактной</em> части,
которая оперирует с <em>ассоциациями</em> <em>по
поводу</em> s(t) и e(t), и интерфейса с органами,
который<em> </em>работает с конкретными кодами<em> </em>s(t)
и e(t).</p>

<p>Если бы система управления была основана "на
правилах", и выполняла только заранее
определённые операции с функциями s(t) и e(t), то она
не имела бы возможности <em>универсального</em>
обучения. Правила можно изменять по мере
накопления опыта. Но проще построить
универсальный мозг - ядро системы управления,
вообще не работающее с функциями s(t), e(t). </p>

<p>Разделение системы управления на систему
взаимодействия с органами и универсальный мозг
приводит к возможности замены органов или замены
содержания их памяти, то есть кодов s(t) и e(t), без
замены алгоритма функционирования
универсального мозга машины. В том числе,
возможна частичная замена или модернизация
органов без перерыва сознания – на лету.</p>

<p>Иерархически каждый орган может обладать
своими органами и мозгом. При этом конструкция
существа представляет собой симбиоз
взаимодействующих органов, для которых также
заданы внутренние правила обмена информацией.
Однако "правила" физического
взаимодействия определяются законами мира и не
могут быть заданы произвольно. При таком подходе
каждый живой нейрон является "органом",
совмещающим функции сенсора и эффектора.</p>

<p> </p>

<h3>Взаимодействие блоков</h3>

<p>Сенсоры выполняют конкретное преобразование
S(t) --&gt; s(t), которое можно интерпретировать как
преобразование воздействия со стороны мира в
код. Эффекторы выполняют конкретное
преобразование e(t) --&gt; E(t), то есть преобразуют код
команды в воздействие на мир. Преобразование s(t)
--&gt; e(t) (<em>поведение</em> системы управления)
выполняет система управления.</p>

<p>Формат данных и сами величины s(t) и e(t) зависят от
устройства датчиков. Эти данные остаются в их
памяти, но не зависят, не контролируется и никак
не используется мозгом. У нашей машины <em>мозг</em>
и <em>память</em> не объединены в один блок, подобный
биологическому мозгу. Абстрактная часть системы
управления - мозг не обрабатывает сигнал s(t) и не
вырабатывает сигнал e(t).</p>

<p>Множество значений s(t) и e(t) для всех датчиков в
определённый момент времени t называется
событием Ev(t). <em>Событие</em> – это внутреннее
представление данных, а не объективное явление.
Если память принадлежит датчикам, то параметр t в
Ev(t) имеет смысл момента времени в прошлом, а не
текущего времени, как в функциях состояния
сенсоров S(t) и эффекторов E(t). Множество данных s(t)
и e(t) – это фиксированное, сохранённое в памяти <em>прошлое</em>.
Поэтому полезно ввести два обозначения для
времени: t – текущее время, tp – ссылка на момент
времени в прошлом.</p>

<p>Непрерывная последовательность событий, все из
которых были похожи на текущее событие в течение
некоторого времени до данного момента t, и
которая завершается событием, похожим на текущее
событие Ev(t), называется узнаваемым<em> процессом.</em>
Процесс – это событие вместе со своей историей. </p>

<p>Датчики сообщают мозгу свои функции узнавания
Ct(tp) (где t – текущее время, tp – все моменты
прошлого). Функция узнавания показывает, в какие
из прошедших моментов времени события Ev(tp) были
похожи на текущее событие Ev(t). Функции Ct(tp) не
содержат информации о том, что и в каком виде было
зафиксировано датчиком. </p>

<p>В ответ мозг сообщает датчикам моменты
прошлого tps, когда узнавание было <em>удачным </em>для
системы в целом. <em>Удачное узнавание</em> - это
такой <em>похожий</em> момент tp в прошлом, <em>после
которого</em> была снижена потребность W.</p>

<p><em>Похожесть</em> или <em>узнавание</em> определяется
при сравнении событий или процессов, а <em>удачность</em>
узнавания – при сравнении величин W,
зарегистрированных после узнавания. </p>

<p align="center"><img src="algorithm_files/al02a.gif" alt="Пример согласованных по времени зависимостей успеха, узнавания, целевой функции &quot;желания&quot;." height="443" width="409">
</p>

<p>Датчики-преобразователи машины, способной к
универсальному обучению, можно по праву назвать
органами, так как они могут обучиться чему угодно
в пределах своих физических способностей, что
было бы невозможно при заранее заданном
алгоритме управления датчиками. </p>

<p>Органы сами хранят свой опыт. Поэтому после
обучения шаблоны правильного поведения остаются
в памяти органа, что разгружает мозг от
"квалифицированного" управления. Другими
словами, по мере обучения мозг не умнеет и не
накапливает знания. </p>

<p>Разумность поведения и способности к обучению
нашего существа зависят от эффективности
органов и от того, как организовано внутреннее
информационное взаимодействия между органами. И
хотя органы могут иметь непосредственную
зависимость друг от друга, в том смысле, что
сигнал s<sub>i</sub>(t) органа i является командой e<sub>j</sub>(t)
= f [s<sub>i</sub>(t)] для органа j, мы не будем
рассматривать такие чисто <em>безусловные
рефлексы</em>.</p>

<p>Система управления вырабатывает команды e(t),
основываясь на данных s(t) и на прежнем опыте
машины. Такая система управления
взаимодействует с органами и не взаимодействует
с внешним миром. Возможный датчик состояния W
самой системы управления или мозга,
вырабатывающий соответствующий сигнал s(t),
функционально является органом, а не частью СУ.</p>

<p align="center"><img src="algorithm_files/al03.gif" alt="Традиционная схема преобразования входящих данных в исходящие действия." height="333" width="333"></p>

<p>Потоки данных s(t) и e(t) скрыты от абстрактной
части системы управления - мозга. Сенсоры и
эффекторы образуют собой интерфейс между миром и
системой управления. А между мозгом и датчиками
должен быть интерфейс преобразующий
"прошлое" tp в "настоящее" t. </p>

<p align="center"><img src="algorithm_files/al04.gif" alt="В традиционной схеме мозг является системой управления для системы управления телом." height="333" width="334">
</p>

<p>Хотя я отделяю систему управления от других
органов, но её можно считать особым органом,
регулирующим общее состояние системы. Также и
мир можно считать органом – генератором или
источником возможных состояний системы,
измеряемых сенсорами S(t). </p>

<p>Сенсор воспринимает сигнал S(t) и вырабатывает
сигнал s(t). Он преобразует своё состояние S(t) в код
s(t).</p>

<p>Система управления (СУ) воспринимает сигнал s(t)
и вырабатывает сигнал e(t). Здесь уже видно, что s(t)
– это не совсем "текущее" состояние СУ, так
как СУ использует всё хранимое в памяти прошлое
для выработки сигнала e(t).</p>

<p>Точно так же есть зависимость от прошлого у
состояний мира, сенсоров и эффекторов. </p>

<p>Эффектор воспринимает сигнал e(t) и вырабатывает
сигнал E(t). Текущим состоянием E(t) можно считать
физическое состояние эффектора, а e(t) является
его информационным состоянием.</p>

<p>Мир воспринимает сигнал E(t) и вырабатывает
сигнал S(t). Мир преобразует задаваемое машиной
состояние E(t) в доступный восприятию машины <em>физический
код</em> S(t). Цикл преобразований замыкается, и мы
получаем круговую диаграмму - другое
представление схемы 3.</p>

<p align="center"><img src="algorithm_files/al05.gif" alt="Равноправная круговая схема &quot;круговорот данных&quot;." height="305" width="542">
</p>

<p>Заметим, что все части этой схемы принадлежат
миру, и она не требует никакого "сознания".
Функционирование мозга тоже не нуждается в
наличии сознания. Круговая схема показывает, что
в схеме машины каналы сенсора и эффектора
размещены симметрично относительно друг друга, и
даже дублируют друг друга. Из рис.4 и рис.5 видно
также, что мир и мозг расположены симметрично по
отношению к блоку из тела и системы управления. </p>

<p align="center"><img src="algorithm_files/al06.gif" alt="Сенсоры и эффекторы являются физическими устройствами, а их память и мозг - информационными." height="362" width="494"></p>

<p>Обведённую пунктирной рамочкой <em>систему
управления</em> по аналогии с биологическим мозгом
можно было бы тоже назвать <em>мозгом</em>, но мы
сохраним это название для <em>центра абстрактного
управления</em>, который выполняет только часть
функций настоящего мозга. Я не объединяю CPU
(центральный процессор) и память в единое
устройство "модель живого мозга", и даже не
стану использовать далее слова "система
управления", так как считаю важным, чтобы
"память" принадлежала органам и была не
видна из центра <em>абстрактного</em> управления.</p>

<p>На рисунке 6 уточнено, что поток данных между
мозгом и интерфейсом эффектора должен быть
двунаправленным, так как мозг получает
ассоциативную информацию Ct(tp) не только о
состоянии сенсоров, но и о состоянии эффекторов. </p>

<p>Мир, сенсоры и эффекторы выполняют прямое
преобразование "по правилам", а мозг решает
косвенную задачу оптимизации совокупности
физических состояний датчиков S(t) и E(t), не
используя даже данных s(t) и e(t).</p>

<p>Для мозга сенсор практически не отличим от
эффектора. Если бы мозг подавал команду tps также и
на сенсор, то в этой структурной схеме сенсор и
эффектор можно, наконец, объединить в одно
двунаправленное устройство "датчик",
интерфейс которого 

</p><ul>
 <li>получает от мозга <em>команду</em> tps, извлекает из
 памяти данные d(tps) (то есть, s(tps) и e(tps)), и подаёт на
 датчик команду d(t)=d(tps)</li>
 <li>получает от датчика и направляет в память
 команду d(t), то есть просто фиксирует состояние
 датчика в момент t, </li>
 <li>извлекает из памяти все d(tp), формирует и
 передаёт мозгу массив Ct(tp).</li>
</ul>

<p>Объединяя сенсор и эффектор в единое
устройство "датчик", мы включаем в него как
физические свойства взаимодействия с миром, так
и функцию интерфейса с мозгом и память. Это и есть
"орган" содержащий свой интерфейс для
взаимодействия с мозгом. </p>

<p align="center"><img src="algorithm_files/al07.gif" alt="Симметричная схема, в которой мозг и внешний мир имеют равноправный доступ к памяти." height="201" width="626"></p>

<p>Возможны разные реализации универсальной
адаптирующейся машины, которая оптимизирует
заданную целевую функцию. Подробности
устройства мозга, памяти, да и самой целевой
функции не имеют принципиального значения. Для
развития сознания достаточно, чтобы у машины
имелись <em>мотивы</em>, а не алгоритмы поведения.
Сознание развивается из ощущений, а не из
физической реализации.</p>

<p> </p>

<h3>Проследим путь данных</h3>

<blockquote>
 <p>В физическом мире происходит взаимодействие
 органов с миром, а в сознании происходит
 ассоциативное возбуждение конкретных
 воспоминаний о прежних ощущениях. Оба этих мира
 находятся вне информационной системы управления
 нашей машиной.</p>
</blockquote>

<p>Физические данные превращаются в информацию в
датчике-преобразователе (сенсоре и эффекторе).</p>

<p>В момент t датчик вырабатывает код d(t),
соответствующий его текущему состоянию D(t).</p>

<p>Код d(t) подаётся на вход памяти датчика. В память
заносятся коды состояния датчиков d(t), а также
численное значение целевой функции W(t), которое
вычисляется на основе текущих состояний
датчиков.</p>

<p>На основе данных d(tp) <em>информационный
интерфейс</em> вырабатывает функцию Ct(tp), имеющую
смысл сравнения текущего процесса со всеми
данными, ранее попавшими в память в моменты tp&lt;t.</p>

<p>Функция Ct(tp) поступает в мозг, который
сопоставляет все такие функции от всех органов, и
находит, какие из моментов в прошлом наиболее
похожи на текущий момент. В эти моменты некое
суммарное значение Ct(tp) максимально.</p>

<p>Из всех похожих моментов мозг выбирает
наиболее успешные моменты tps, которые в прошлом
привели к последующему лучшему значению целевой
функции W. Данные из канала W доступны мозгу в виде
сравнимых чисел.</p>

<p>Моменты tps могут различаться для разных групп
датчиков. Благодаря этому мозг способен
подобрать такой лучший момент в прошлом, который
синтезирован из различных фрагментов истории, и
который лучше соответствует текущей ситуации,
чем любая из ситуаций, хранимых в памяти.</p>

<p>Получив от мозга значение момента времени tps,
память (датчика) выдаёт на датчик код его
состояния d(t)=d(tps) в этот момент.</p>

<blockquote>
 <p>Именно этот <em>синтезированный</em> мозгом момент
 прошлого (не всегда совпадающий с текущим
 моментом и с реальным прошлым) может стать
 текущим осознаваемым ощущением, так как он
 строго ассоциативно привязан к осознанным
 ощущениям или осмысленным понятиям, то есть, он
 имеет смысл. Практически, позитивный опыт
 существования в физическом мире приводит к тому,
 что почти все текущие ощущения уже были испытаны
 ранее и способны быть осознаваемыми.</p>
</blockquote>

<p>Сенсор может проигнорировать эту команду, а
эффектор может её исполнить, то есть выполнить
соответствующее действие по отношению к миру.</p>

<p>Эффекторы устроены так, что тот же самый,
неизменённый код команды d(t) является
подтверждением её успешного выполнения.
Выполненная команда и есть <em>код состояния</em>
эффектора. Если команда была некорректной или
что-то другое помешало её исполнению, то эффектор
может оказаться в другом состоянии. В этом случае
входная и выходная команды различаются.</p>

<p>Новый цикл обработки данных начинается с
поступления состояний датчиков в память.
Буквальное последовательное исполнение этого
цикла не обязательно, так как, благодаря привязке
к общему времени все компоненты машины могут
работать асинхронно. </p>

<p> </p>

<h2>Структура данных</h2>

<p>Описанные выше системы самообучающейся машины,
в конце концов, обрабатывают <em>данные</em>.
Математическое описание этой обработки не
требует разделения машины на органы,
разграничения их функций, не требует упоминания
того, что <em>данные хранятся в памяти</em> и других
подобных ссылок на устройство машины. Даже
представления о <em>времени</em> и о <em>работе в
реальном времени</em> относятся не к алгоритму, а к
его применению.</p>

<p>Однако я буду использовать привязку
обозначений и операций к машине, чтобы уменьшить
формальность довольно непрозрачного и
усложнённого (на первый взгляд) алгоритма. </p>

<p> </p>

<h4>Данные</h4>

<p>Итак, имеются <em>данные</em> <big>di(t)</big>, где i –
номер датчика – <em>источника данных</em>, t – время.
Параметр <em>время</em> используется для
синхронизации выбора данных из памяти
независимо работающих датчиков. Синхроность
хранения данных можно обеспечить тем, что метка
времени заносится в память датчика в момент
поступления данных, или путём одновременного
считывания данных всех датчиков в заданные
моменты времени. Этот вопрос относится к
реализации алгоритма.</p>

<p>В текущий момент времени t=tc величина di(t)
принимает значение <em>текущего</em> <em>состояния
датчика</em> i. Для t&gt;tc данные могут задаваться
путём ссылок на моменты времени <em>в прошлом</em>
t&lt;tc, например </p>

<p align="center"><big>d(t2) <font face="Symbol">¬</font> d(t1), t2&gt;tc, t1&lt;tc</big></p>

<p>Такое <em>упреждающее</em> задание данных имеет
смысл <em>прогноза</em>: в момент t2 ожидается
поступление таких же данных, как данные,
полученные в момент t1. </p>

<p>При t&lt;tc данные не изменяются. Они просто <em>хранятся
в памяти</em>.</p>

<p> </p>

<h4>Целевая функция</h4>

<p>Целевую функцию <em>удовольствия</em> P(t) может
вырабатывать специальный датчик. В качестве
алгоритмической реализации такого датчика можно
выполнять вычисление функции P(t) в момент
поступления данных t=tc. <em>Текущее удовольствие</em>
P(tc) - это не функция над содержимым памяти, а
функция текущего состояния датчиков.</p>

<p align="center"><big>P (tс) = f [ d1(tс), d2(tс), … ]</big></p>

<p>Функция <em>удовольствия</em> P противоположна
функции <em>потребности </em>W. Мозг нашей машины
должен обеспечить максимальное среднее значение
P(t). Среднюю величину P(t) в интервале времени от tc
до tc+T назовём <em>предстоящим успехом</em> S(t).</p>
<div align="center"><center>

<table border="0" cellpadding="0" cellspacing="0">
 <tbody><tr>
 <td></td>
 <td valign="bottom"><p align="center"><big>t+T</big></p></td>
 <td></td>
 </tr>
 <tr>
 <td><p align="right"><big>S(t) = 1/T</big></p></td>
 <td><p align="center"><font face="Symbol"><big><big><big>т</big></big></big></font></p></td>
 <td><big>P(t) dt</big></td>
 </tr>
 <tr>
 <td></td>
 <td valign="top"><p align="center"><big>t</big></p></td>
 <td></td>
 </tr>
</tbody></table>
</center></div>

<p> </p>

<h4>Узнавание</h4>

<p>При t <font face="Symbol">№</font> tc данные различных
датчиков несопоставимы. Возможно только
сравнение состояний одного датчика,
зарегистрированных в различные моменты времени.
Величина <em>функции сравнения</em> Ci(t1,t2)
пропорциональна <em>похожести</em> данных,
сохранённых в памяти датчика i в моменты t1 и t2.</p>

<p align="center"><big>0 <font face="Symbol">Ј</font> Ci (t1, t2) <font face="Symbol">Ј</font>
1</big></p>

<p>Если di(t1) = di(t2), то Ci (t1, t2) = 1. Данные в моменты t1 и t2
считаются похожими, если Ci (t1, t2) <font face="Symbol">і</font>
C0, где C0: 0 &lt; C0 <font face="Symbol">Ј</font> 1 - <em>порог
узнавания</em>. К примеру, C0=0.5. В момент t1 данные
первого датчика d1(t1) похожи на текущие данные d1(tc),
если C1(t1, tc) <font face="Symbol">і</font> C0.</p>

<p> </p>

<h4>Процесс</h4>

<p><em>Процессом</em> t1 называется участок данных di(t),
включающий точку t1. Для обозначения процесса
используется ссылка на момент времени t1. К этому
моменту процесс продолжается, (то есть, обычно,
узнаётся) уже некоторое время. Сравнение
процессов характеризуется <em>историей </em>Hi</p>

<p align="center"><big>Hi (t1, t2) = max(h)</big></p>

<p>где h - это продолжительность совпадения
процессов: Ci (t1-<font face="Symbol">D</font>t, t2-<font face="Symbol">D</font>t)
<font face="Symbol">і</font> C0, <font face="Symbol">D</font>t = 0 <font face="Symbol">...</font>
h</p>

<p><em>История</em> – это время, в течение которого
сравниваемые процессы были <em>похожими</em>. </p>

<p> </p>

<h4>Группа датчиков</h4>

<p>Для проверки одновременного узнавания
процессов, сохранённых в памяти нескольких
датчиков, используется <em>группа (множество)
датчиков</em> </p>

<p align="center"><big>Mj = [ i1, i2, … , iJ ]</big></p>

<p>i1, i2 … - номера датчиков, входящих в данную
группу. </p>

<p>Сравнение в группе Mj определяется наиболее
короткими процессами. Если узнавания нет хотя бы
у одного датчика, то узнавания нет и в группе. </p>

<p align="center"><big>Hj (t1, t2) = min [ Hi (t1, t2) ], i <font face="Symbol">М</font>
Mj</big></p>

<p>Мы будем использовать индекс j для обозначения
номера группы датчиков, и индекс i для
обозначения индивидуального датчика.</p>

<p> </p>

<h4>Критерий узнавания </h4>

<p>Группа Mj вместе с приписанным к ней <em>порогом
истории</em> hj называется критерием узнавания. </p>

<p align="center"><big>Aj = ( Mj, hj )</big></p>

<p>Процессы t1 и t2 похожи по критерию Aj, если Hj (t1, t2) <font face="Symbol">і</font> hj. Процесс t1 <em>узнаётся</em>, то есть,
он похож на текущий процесс tc, если хотя бы для
одного из <em>заданных</em> критериев узнавания</p>

<p align="center"><big>Hj (t1, tc) <font face="Symbol">і</font> hj</big></p>

<p>Все найденные в памяти процессы, которые
узнаются по критерию Aj, назовём <em>списком
узнаваемых процессов</em> или <em>списком Aj</em>.</p>

<p> </p>

<h4>Варианты продолжения текущего процесса</h4>

<p>Для всех Nj процессов t1, t2, … , узнаваемых по
критерию Aj можно рассчитать средний предстоящий
успех</p>

<p align="center"><big>Sj = [ S(t1) + S(t2) + … ] / Nj</big></p>

<p>В статистическом смысле этот успех зависит от
прошлого t &lt; tс и от начального участка будущего
t: tc<font face="Symbol"> Ј</font> t &lt; tc+T. Узнаваемые по Aj
процессы могут иметь различное будущее. </p>

<p>Разделим процессы Aj по вариантам будущего в
пределах tc … tc+dt. Для этого найдём все процессы,
которые в интервале от tc до tc+dt похожи (по
критерию Aj) на первый процесс t1 из <em>списка
процессов Aj</em>. Затем, среди оставшихся процессов
найдём все процессы, похожие в момент tc+dt на
первый из оставшихся процессов. И так далее, до
исчерпания списка узнаваемых процессов. Чем
меньше глубина прогноза dt, тем меньше различных
вариантов будущего будет обнаружено.</p>

<p>Допустим, всего найдено K вариантов продолжения
текущего процесса, которые можно обозначить
ссылками на моменты времени t1, t2, … tK. Отдельные
экземпляры процесса tk обозначим вторым индексом:
tk1, tk2, … Для каждого варианта tk рассчитаем
предстоящий успех </p>

<p align="center"><big>Sk = [ S(tk1) + S(tk2) … ] / Nk</big></p>

<p>где Nk – число экземпляров варианта k.</p>

<p>Также можно оценить дисперсию определения
средней величины успеха Sk</p>

<p align="center"><big>Dk = { [S(tk1)-Sk]<sup>2</sup> + [S(tk2)-Sk]<sup>2</sup> + … } /
Nk<sup>2</sup></big></p>

<p>В знаменателе стоит квадрат длины выборки, так
как мы определяем не дисперсию успеха, а <em>дисперсию
средней величины</em> успеха. Дисперсия отличается
от нуля из-за конечности длины выборки. Таким
образом, мы определили варианты прогноза
развития процесса Aj, ожидаемый успех каждого
варианта Sk, и точность оценки этого успеха Dk.</p>

<p> </p>

<h4>Выбор более успешного варианта</h4>

<p>Для двух прогнозов Sk1 и Sk2, основанных на двух
вариантах будущего, рассчитаем <em>разрешение </em>R(1,2),
которое характеризует статистическую
надёжность того, что величины Sk1 и Sk2 различаются. </p>

<p align="center"><big>R (1, 2) = (Sk1-Sk2) / sqrt(Dk1+Dk2)</big></p>

<p>Если R(1,2) <font face="Symbol">і</font> R0, то прогноз k1 <em>достоверно</em>
<em>успешнее</em>, чем прогноз k2. Величина R0 – это
среднеквадратичный <em>порог разрешения</em>.
Например, R0=1.</p>

<p><em>Разрешением</em> Rj критерия Aj считается лучшее
из разрешений R (k1, k2), найденное для всех пар
прогнозов </p>

<p align="center"><big>Rj = max [ R (k1, k2) ], k1<font face="Symbol"> Ј </font>K, k2<font face="Symbol"> Ј </font>K</big></p>

<p>Если Rj &lt; R0, то критерий Aj не принимается во
внимание при поиске прогноза. Это один из
способов отсева многочисленных критериев
узнавания, среди которых нужно использовать
наиболее достоверные. </p>

<p>Максимально успешный вариант продолжения
текущего процесса, определённый по критерию Aj,
назовём <em>предлагаемым прогнозом</em>.</p>

<p>Можно доказать, что для двух критериев A1 и A2,
имеющих достаточное разрешение (R1 <font face="Symbol">і</font>
R0 и <span>R</span>2 <font face="Symbol">і</font> R0), и обладающих
следующим свойством <em>вложенности</em></p>

<p align="center"><big>A1 <font face="Symbol">К</font> <span>A</span>2, то есть M1 <font face="Symbol">К</font> <span>M</span>2 и h1 <font face="Symbol">і</font> <span>h</span>2</big></p>

<p>прогноз, <em>предлагаемый</em> A1 не хуже, чем
прогноз A2. Есть и другие способы уменьшить число
надёжных критериев <em>выбора поведения</em>. Нужное
поведение реализуется при <em>исполнении</em>
датчиками наиболее <em>выгодного прогноза</em>,
отличающегося максимальным (с точностью до
разрешения) ожидаемым успехом. </p>

<p> </p>

<h4>Синтез выгодного процесса, которого нет в
памяти</h4>

<p>Описанная структура данных и способ выбора
наиболее успешного прогноза позволяет
синтезировать действие, которое не встречалось
ранее, и, предположительно, является более
выгодным, чем все имеющиеся в памяти действия. </p>

<p>Если достоверные критерии <span>A</span>1 и A2
предлагают одинаковый прогноз для общих
датчиков M = <span>M</span>1 <font face="Symbol">З</font> M2 или не
содержат общих датчиков, то для датчиков M1 нужно
выбрать действия, предлагаемые критерием A1, а для
датчиков из группы M2 нужно выбрать действия,
предлагаемые критерием A2. </p>

<p>В силу независимости прогнозирования по
критериям A1 и A2, эти действия могли ранее никогда
не встречаться одновременно.</p>

<p>Возможность одновременного исполнения
нескольких процессов, сохранённых в памяти в
разное время, обеспечивает прохождение этим
алгоритмом <em><a href="http://webcenter.ru/%7Ekorn/mind/consciousness.html#selfawaretest">теста на
осознавание себя</a></em>. </p>

<p> </p>

<hr width="80%">

<p>Далее можно показать, каким образом данный
алгоритм, обслуживая достаточно эффективные
органы, решает задачи универсального обучения
вплоть до долговременного запоминания в
отсутствие особой <em>долговременной</em> или <em>структурированной</em>
<em>памяти</em> и до формирования <em>знаковой системы</em>.
Многие из интересных вопросов уже рассмотрены на
страницах этого сайта.</p>

<p><strong><a href="http://webcenter.ru/%7Ekorn/post/email.html">Евгений Корниенко</a><br>
</strong>08.2001</p>

<p> </p>

<p><strong><a href="http://webcenter.ru/%7Ekorn/mind/danger.html">Опасно разумен <img src="algorithm_files/go.gif" border="0" height="15" width="15"></a></strong><br>
<a href="http://webcenter.ru/%7Ekorn/mind/question.html">Вопросы о природе сознания <img src="algorithm_files/go.gif" border="0" height="15" width="15"></a><br>
<a href="http://webcenter.ru/%7Ekorn/files/tmpbrain-2003-09.zip"><img src="algorithm_files/alife.gif" alt="made with Delphi 7" align="left" border="0" height="30" width="43"></a> Самообучающаяся
бабочка, <a href="http://webcenter.ru/%7Ekorn/files/tmpbrain-2003-09.zip">tmpbrain.zip <img src="algorithm_files/go.gif" alt="Пример программы" border="0" height="15" width="15"></a><br>
Текст программы на DELPHI: <a href="http://webcenter.ru/%7Ekorn/files/synt-2003-09.zip">synt.zip <img src="algorithm_files/go.gif" alt="Полный комплект для программиста" border="0" height="15" width="15"></a></p>

<hr width="80%">

<p><!--webbot bot="Navigation" S-Type="parent" S-Orientation="horizontal" S-Rendering="text" B-Include-Home="FALSE" B-Include-Up="FALSE" startspan --><nobr>[&nbsp;<a href="http://webcenter.ru/%7Ekorn/mind/consciousness.html">Механизмы&nbsp;сознания</a>&nbsp;]</nobr> <nobr>[&nbsp;<a href="http://webcenter.ru/%7Ekorn/mind/articles.html">Статьи&nbsp;о&nbsp;природе&nbsp;сознания</a>&nbsp;]</nobr> <nobr>[&nbsp;<a href="http://webcenter.ru/%7Ekorn/mind/ai.html">Искусственное&nbsp;сознание</a>&nbsp;]</nobr> <nobr>[&nbsp;<a href="http://webcenter.ru/%7Ekorn/ai-post/index.html">Переписка</a>&nbsp;]</nobr> <nobr>[&nbsp;<a href="http://webcenter.ru/%7Ekorn/reading/index.html">Что&nbsp;читать</a>&nbsp;]</nobr><!--webbot bot="Navigation" endspan i-checksum="26384" --></p>

<p><a href="http://webcenter.ru/%7Ekorn/index.html"><img src="algorithm_files/home.gif" alt="Механизмы... Е.Корниенко" border="0" height="27" width="76"></a></p>


</body></html>